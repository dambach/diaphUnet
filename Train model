def train_model(model, xtrain, ytrain, xtest, ytest, num_epoch, batch, loss_fn, save_epoch):
  optimizer = torch.optim.Adam(model.parameters(), lr = 1e-4,  weight_decay = 1e-2)
  train_losses = []
  test_losses = []
  acc_train = []
  acc_test = []
  dice_train = []
  dice_test = []
  
  for epoch in range(1, num_epoch + 1):
    t1 = time.time()
    train_loss = 0.0
    test_loss = 0.0
    
    for u, v, mu, mv in zip(xtrain, ytrain, xtest, ytest):
      train_loader = torch.utils.data.DataLoader(dataset = u, batch_size = batch, shuffle = False)
      test_loader = torch.utils.data.DataLoader(dataset = v, batch_size = int(batch/2), shuffle = False)
      mtrain_loader = torch.utils.data.DataLoader(dataset = mu, batch_size = batch, shuffle = False)
      mtest_loader = torch.utils.data.DataLoader(dataset = mv, batch_size = int(batch/2), shuffle = False)
    
      num_correct = 0
      num_pixels = 0
      dice_score = 0
      model.train()
      for img1, mimg1 in zip(train_loader, mtrain_loader):
        img1 = img1.to(device)
        optimizer.zero_grad()
        y_pred1 = model(img1)
        mimg1 = Variable(mimg1).type(torch.FloatTensor).to(device)
        loss = loss_fn(y_pred1, mimg1)
        loss.backward()
        optimizer.step()
        train_loss += loss.item()*img1.size(0)
        
        with torch.no_grad():
          img1 = img1.to(device)
          mimg1 = mimg1.to(device)
          preds = torch.sigmoid(y_pred1)
          preds = (preds > 0.5).float()
          num_correct += (preds == mimg1).sum()
          num_pixels += torch.numel(preds)
          dice_score += (2 * (preds * mimg1).sum()) / ((preds + mimg1).sum() + 1e-8)
          dice_score /= len(train_loader)
          acc1 = num_correct/num_pixels*100
          dice1 = 1 - dice_score
      
      num_correct = 0
      num_pixels = 0
      dice_score = 0
      model.eval()
      for img2, mimg2 in zip(test_loader, mtest_loader):
        img2 = img2.to(device)
        y_pred2 = model(img2)
        mimg2 = Variable(mimg2).type(torch.FloatTensor).to(device)
        loss = loss_fn(y_pred2, mimg2)
        test_loss += loss.item()*img2.size(0)
      
        with torch.no_grad():
          img2 = img2.to(device)
          mimg2 = mimg2.to(device)
          preds = torch.sigmoid(y_pred2)
          preds = (preds > 0.5).float()
          num_correct += (preds == mimg2).sum()
          num_pixels += torch.numel(preds)
          dice_score += (2 * (preds * mimg2).sum()) / ((preds + mimg2).sum() + 1e-8)
          dice_score /= len(test_loader)
          acc2 = num_correct/num_pixels*100
          dice2 = 1 - dice_score
  
    acc_train.append(acc1)
    acc_test.append(acc2)
    dice_train.append(dice1)
    dice_test.append(dice2)
    train_loss = train_loss/len(train_loader.sampler) 
    test_loss = test_loss/len(test_loader.sampler)
    
    train_losses.append(train_loss)
    test_losses.append(test_loss)
    t2 = time.time()  
    if epoch % save_epoch == 0:
      path = '/content/drive/MyDrive/Colab Notebooks/Data/model_12' + str(epoch) + '.pth'
      torch.save(model, path)
      print('Epoch : {} Train Loss : {:.4f} Test Loss : {:.4f} Accuracy train : {:.4f} Accuracy test : {:.4f} Dice train : {:.4f} Dice test : {:.4f} Temps : {:.4f} min'.format(epoch, train_loss, test_loss, acc1, acc2, dice1, dice2, (t2-t1)/60))
      fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(20, 15),
                             gridspec_kw={'width_ratios': [3, 3],
                                          'height_ratios': [3, 3],
                                          'wspace': 0.4,
                                          'hspace': 0.4})
      # Loss
      ax[0][0].plot(list(range(epoch)), train_losses[:epoch], label = 'train_losses')
      ax[0][0].plot(list(range(epoch)), test_losses[:epoch], label = 'test_losses')
      ax[0][0].set_xlabel("Epoch", fontsize = 18)
      ax[0][0].set_ylabel("Loss", fontsize = 18)
      ax[0][0].set_xlim([0, epoch-1])
      ax[0][0].set_ylim([0, 1.5*max(max(train_losses), max(test_losses))])
      ax[0][0].legend(prop = {'size':16}, loc = 'best')
 
      # Précision
      ax[0][1].plot(list(range(epoch)), acc_train, label = 'Accuracy train')
      ax[0][1].plot(list(range(epoch)), acc_test, label = 'Accuracy test')
      ax[0][1].set_xlabel("Epoch", fontsize = 18)
      ax[0][1].set_ylabel("Accuracy", fontsize = 18)
      ax[0][1].legend(prop = {'size':16}, loc = 'lower right')
 
      # Image prédite
      J = np.random.randint(len(y_pred2)-1)
      ax[1][0].imshow(y_pred2[J,0,:,:].cpu().detach().numpy())
      ax[1][0].set_title('Image prédite')
      ax[1][0].axis('off')

      # Image vérité terrain
      #image = exposure.adjust_gamma(mimg2[J,0,:,:].cpu().detach().numpy(), gamma = 14)
      ax[1][1].imshow(mimg2[J,0,:,:].cpu().detach().numpy())
      ax[1][1].set_title('Image prédite')
      ax[1][1].axis('off')
 
      plt.show()
      plt.pause(1e-99)
      if test_losses[-3] < test_losses[-2] and test_losses[-2] < test_losses[-2]:
        print(test_losses[-3:])
        break
    else:
      print('Epoch : {} Train Loss : {:.4f} Test Loss : {:.4f} Accuracy train : {:.4f} Accuracy test : {:.4f} Dice train : {:.4f} Dice test : {:.4f} Temps : {:.4f} min'.format(epoch, train_loss, test_loss, acc1, acc2, dice1, dice2, (t2-t1)/60))
